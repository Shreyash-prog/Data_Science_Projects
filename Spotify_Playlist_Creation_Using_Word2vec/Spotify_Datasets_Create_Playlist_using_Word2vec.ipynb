{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective : In this notebook we will play around with the spotify datasets and do the following things\n",
    "                \n",
    "    1. Read the pickle file of summarised datasets\n",
    "    2. Train a word 2 vec model using skip gram with window size as a hyperparametrs\n",
    "    3. Play around with the vectors received from this excercise \n",
    "    4. Try creating two function which return most similar songs to particular songs\n",
    "    5. Take 3 songs as list and return a playlist of 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ash\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "### Load the required packages in the required format\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The dataset is loaded succesfully\n",
      " The shape of the dataset is as follows (229180, 3)\n",
      "                            user_id      playlistname  \\\n",
      "0  00055176fea33f6e027cd3302289378b              favs   \n",
      "1  0007f3dd09c91198371454c608d47f22              2014   \n",
      "2  0007f3dd09c91198371454c608d47f22         Fav songs   \n",
      "3  0007f3dd09c91198371454c608d47f22         Sad songs   \n",
      "4  000b0f32b5739f052b9d40fcc5c41079  Agnetha Fältskog   \n",
      "\n",
      "                                           trackname  \n",
      "0  [9619, 2591, 46683, 9620, 1138379, 37346, 6335...  \n",
      "1                [174985, 1541, 878603, 17550, 5303]  \n",
      "2  [1854415, 174985, 1684382, 955407, 19605, 1482...  \n",
      "3                                 [1510871, 1448429]  \n",
      "4                                  [1281658, 487582]  \n"
     ]
    }
   ],
   "source": [
    "### Load the pickled datasets \n",
    "with open('spotify_summary.pickle','rb') as dataset:\n",
    "    spotify_summary = pickle.load(dataset)\n",
    "    print (\" The dataset is loaded succesfully\")\n",
    "    print (\" The shape of the dataset is as follows\",spotify_summary.shape)\n",
    "    print (spotify_summary.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data is ready for gensim models\n",
      "The number of input playlists we have are as follows : 229180\n"
     ]
    }
   ],
   "source": [
    "### Gensim takes input as a list of list. Our tracknames are already a list convert them to list of list\n",
    "spotify_wrd2vec_input = [ x for x in spotify_summary['trackname']]\n",
    "print (\"Input data is ready for gensim models\")\n",
    "print (\"The number of input playlists we have are as follows :\",len(spotify_wrd2vec_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tip : Always read the help before using any function so we will have a look at the word2vec functions\n",
    "# help(gensim.models.Word2Vec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training has started\n",
      "Model Trainin Finished\n"
     ]
    }
   ],
   "source": [
    "### Define traing the word 2 vec model we will use Skip Gram using negative sampling as oftmax can be slow\n",
    "# seed = 1000, hs = 0,negative = 10,workers=10,iter = 100)\n",
    "### Skip Gram : Predict Context given the middle word works well with infrequent datasets. Good idea for songs as some songs may ne liked by a few users oly\n",
    "print (\"Model Training has started\")\n",
    "model = gensim.models.Word2Vec(spotify_wrd2vec_input, size = 200 , window = 4 , min_count = 15,\n",
    "                               seed = 1000, hs = 0,negative = 10,workers=16,iter = 100)\n",
    "print (\"Model Trainin Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dumping the model succesful \n",
      " The model is dumped at this location : C:\\Users\\ash\\Desktop\\NLP-DL\n"
     ]
    }
   ],
   "source": [
    "### Pickle the model datasets and save it to a pickle file \n",
    "\n",
    "with open('model_spotify_word2vec.pickle','wb') as model_file:\n",
    "    pickle.dump(model,model_file)\n",
    "    print (\" Dumping the model succesful \")\n",
    "    print (\" The model is dumped at this location :\",os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track dict has 1866246 observations\n",
      "Track dict has 1978500 observations\n"
     ]
    }
   ],
   "source": [
    "### From the dump load the model dictionary and model pickle files\n",
    "with open('model_spotify_word2vec.pickle','rb') as model_file:\n",
    "    model_spotify = pickle.load(model_file)\n",
    "\n",
    "### Load the pickle files stored for song to numeric \n",
    "with open('track_map_dict.pickle','rb') as dict1:\n",
    "    track_dict= pickle.load( dict1)\n",
    "print (\"Track dict has {} observations\".format(len(track_dict)))\n",
    "#### Load the prcikle file for artist to numeric\n",
    "with open('track_map_comp_dict.pickle','rb') as dict2:\n",
    "    track_map_comp_dict = pickle.load(dict2)\n",
    "print (\"Track dict has {} observations\".format(len(track_map_comp_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function which return similar songs to a particular songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define a function which takes as input songs from list and returns similar songs\n",
    "def similar_songs(songname,n):\n",
    "    ''' Gets the songname from user and return the n songs similar'''\n",
    "    song_id = track_dict[songname]\n",
    "    print (\"Searching for songs similar to :\",songname)\n",
    "    \n",
    "    similar = model_spotify.most_similar(song_id,topn = n)\n",
    "    print (\"Similar songs are as follow\")\n",
    "    for i in similar[:]:\n",
    "        print (track_map_comp_dict[i[0]])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function which takes list of songs and creates playlist for the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define a function which takes as input songs from list and returns similar songs\n",
    "def create_play_list(list_songs,n):\n",
    "    ''' Gets the songname from user and return the 5 songs similar'''  \n",
    "    list1 = []\n",
    "    for i in list_songs:\n",
    "        list1.append(track_dict[i])      \n",
    "        \n",
    "    print (\"Searching for songs similar to :\",list_songs)\n",
    "    \n",
    "    similar = model_spotify.most_similar(positive = list1,topn = n)\n",
    "    print (\"Playlist based on your list is as follows\")\n",
    "    for i in similar[:]:\n",
    "        print (track_map_comp_dict[i[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets check out results for my favourite songs list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ash\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "2020-05-13 17:08:33,136 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for songs similar to : ['wonderwall', 'paradise', 'yellow', 'let her go', 'fireflies']\n",
      "Playlist based on your list is as follows\n",
      "world spins madly on\n",
      "you and your heart\n",
      "wouldn't it be nice - 1999 - remaster\n",
      "where the streets have no name - unplugged\n",
      "wonderwall - remastered\n",
      "yellow - live\n",
      "wherever you will go - acoustic\n",
      "won't go home without you\n",
      "you are the best thing\n",
      "you and i both\n"
     ]
    }
   ],
   "source": [
    "create_play_list(['wonderwall','paradise','yellow','let her go','fireflies'],10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets check the results for a different music taste - Classic Metal | Rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for songs similar to : ['enter sandman', 'fade to black', 'kashmir']\n",
      "Playlist based on your list is as follows\n",
      "fear of the dark - 1998 remastered version\n",
      "eye of the tiger\n",
      "for whom the bell tolls\n",
      "fear of the dark\n",
      "fairies wear boots\n",
      "feel good inc\n",
      "du hast\n",
      "even flow\n",
      "fuel\n",
      "entre dos tierras\n",
      "ett slag färgat rött\n",
      "everlong\n",
      "fade to black - instrumental version\n",
      "fortunate son\n",
      "estranged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ash\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "create_play_list(['enter sandman','fade to black','kashmir'],15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a different list of songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for songs similar to : ['hey you', 'time', 'hypnotised', 'fix you']\n",
      "Playlist based on your list is as follows\n",
      "hänsyn\n",
      "holy dread!\n",
      "hon har ett sätt - 1998 digital remaster\n",
      "high speed\n",
      "highway of endless dreams\n",
      "i am a man of constant sorrow - o brother, where art thou? soundtrack/with band\n",
      "holiday\n",
      "gap\n",
      "human\n",
      "i always was your girl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ash\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "create_play_list(['hey you','time','hypnotised','fix you'],10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  find out similar songs Kashmir by Led Zepplin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for songs similar to : kashmir\n",
      "Similar songs are as follow\n",
      "kashmir - live: o2 arena, london - december 10, 2007\n",
      "immigrant song\n",
      "keep talking - 2011 remastered version\n",
      "karma police\n",
      "joker and the thief\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ash\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "similar_songs('kashmir',5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highlighting the Problems with current datasets and next steps for further \n",
    "\n",
    "1. Training Data is not clean and has lot of similar songs with different names. We could try to restrict the version of songs to 1 or 2 max based on frequency for example\n",
    "   SOngs :  kashmir , kashmir - live: o2 arena, london - december 10, 2007\n",
    "   \n",
    "2. Songs with similar names can be of different taste based on the artist names. We should create vocab by combining strings of tracknames with the artist names\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
